{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To collect 70 files in one file, glob lib. used.\n",
    "\n",
    "import glob\n",
    "\n",
    "read_files = glob.glob('C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Diabetes-Data\\\\*.txt')\n",
    "\n",
    "with open('C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Data_Mining\\\\ererse.txt', 'w') as outfile:\n",
    "    for f in read_files:\n",
    "        with open(f, 'r') as infile:\n",
    "            outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29330, 1)\n"
     ]
    }
   ],
   "source": [
    "#To check the shape of the file, we print (data.shape)\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(r\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Data_Mining\\\\ererse.txt\",header=None)\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To assign unique User ID to each file, we created a counter.And read all the 70 \n",
    "#files again. After reading, we assigned user ID and then we wrote all the lines to another file.\n",
    "\n",
    "import glob\n",
    "\n",
    "read_files = glob.glob('C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Diabetes-Data\\\\*.txt')\n",
    "with open('C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Data_Mining\\\\ererse.txt', 'w') as file:\n",
    "    sayac = 0\n",
    "    for f in read_files:\n",
    "        sayac += 1\n",
    "        with open(f, 'r') as dosya:\n",
    "            liste = dosya.readlines()\n",
    "            for i in liste:\n",
    "                file.write(str(sayac) +\",\"+ i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Date   Time  Code Value\n",
      "0       1,04-21-1991   9:09    58   100\n",
      "1       1,04-21-1991   9:09    33   009\n",
      "2       1,04-21-1991   9:09    34   013\n",
      "3       1,04-21-1991  17:08    62   119\n",
      "4       1,04-21-1991  17:08    33   007\n",
      "...              ...    ...   ...   ...\n",
      "29325  70,05-09-1989  08:00    33   001\n",
      "29326  70,05-09-1989  08:00    34   007\n",
      "29327  70,05-10-1989  08:00    34   007\n",
      "29328  70,05-11-1989  08:00    34   007\n",
      "29329  70,05-12-1989  08:00    34   007\n",
      "\n",
      "[29330 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#By using sep parameter, we splitted the columns.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(r\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Data_Mining\\\\ererse.txt\",sep=\"\\t\",header=None)\n",
    "data.columns=[\"Date\",\"Time\",\"Code\",\"Value\"]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Time  Code Value User ID        DATE\n",
      "0       9:09    58   100       1  04-21-1991\n",
      "1       9:09    33   009       1  04-21-1991\n",
      "2       9:09    34   013       1  04-21-1991\n",
      "3      17:08    62   119       1  04-21-1991\n",
      "4      17:08    33   007       1  04-21-1991\n",
      "...      ...   ...   ...     ...         ...\n",
      "29325  08:00    33   001      70  05-09-1989\n",
      "29326  08:00    34   007      70  05-09-1989\n",
      "29327  08:00    34   007      70  05-10-1989\n",
      "29328  08:00    34   007      70  05-11-1989\n",
      "29329  08:00    34   007      70  05-12-1989\n",
      "\n",
      "[29330 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#But in Date column, we couldnâ€™t split the User Id and Date. Thatâ€™s why, str.split \n",
    "#function has been used. Here, after comma, the data has been split into columns.\n",
    "#Then dropped the old Date column.\n",
    "\n",
    "new = data[\"Date\"].str.split(\",\", n = 1, expand = True)\n",
    "data[\"User ID\"]= new[0]\n",
    "data[\"DATE\"]= new[1]\n",
    "data.drop(columns =[\"Date\"], inplace = True)\n",
    "\n",
    "#To use it later, we save it in a file namely 29330\n",
    "data.to_csv(r\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Data_Mining\\\\29330.txt\", index=False )\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Time  Code Value User ID        DATE\n",
      "0       9:09    58   100       1  04-21-1991\n",
      "1       9:09    33   009       1  04-21-1991\n",
      "2       9:09    34   013       1  04-21-1991\n",
      "3      17:08    62   119       1  04-21-1991\n",
      "4      17:08    33   007       1  04-21-1991\n",
      "...      ...   ...   ...     ...         ...\n",
      "29171  08:00    33   001      70  05-09-1989\n",
      "29172  08:00    34   007      70  05-09-1989\n",
      "29173  08:00    34   007      70  05-10-1989\n",
      "29174  08:00    34   007      70  05-11-1989\n",
      "29175  08:00    34   007      70  05-12-1989\n",
      "\n",
      "[29176 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#We created a list that contains the codes that are meaningful to us, namely, codes.\n",
    "#According to this list, we filtered the data with isin function.\n",
    "#Reindex the data with index parameter. Then, saved it in a file namely,29176-Date\n",
    "\n",
    "codes=[33,34,35,48,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72]\n",
    "filter=data[\"Code\"].isin(codes)\n",
    "data=data[filter]\n",
    "data.index=range(0,len(data))\n",
    "print(data)\n",
    "data.to_csv(r\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Data_Mining\\\\29176-Date.txt\", index=False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   User ID  Count\n",
      "0       70  29176\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(r\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Data_Mining\\\\29176-Date.txt\")\n",
    "\n",
    "#unique() function is used to find the unique elements\n",
    "numofUSER=data[\"User ID\"].unique()\n",
    "\n",
    "#we count the total attributes\n",
    "count=0\n",
    "for a in data[\"Code\"]:\n",
    "    count +=1\n",
    "df=pd.DataFrame([len(numofUSER),count]).T\n",
    "df.columns=[\"User ID\", \"Count\"]\n",
    "df.to_csv(r\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Data_Mining\\\\.info.txt\", index=False, header=True)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Time  Code  Value\n",
      "User ID                   \n",
      "1         943   943    943\n",
      "2         761   761    761\n",
      "3         290   290    290\n",
      "4         294   294    294\n",
      "5         294   294    294\n",
      "...       ...   ...    ...\n",
      "66        239   239    239\n",
      "67        967   967    967\n",
      "68        693   693    693\n",
      "69         49    49     49\n",
      "70        341   341    341\n",
      "\n",
      "[70 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(r\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Data_Mining\\\\29176-Date.txt\")\n",
    "grup=data.groupby(\"User ID\")\n",
    "genel=grup.count()\n",
    "\n",
    "genel.columns=[\"Time\",\"Code\",\"Value\",\"DATE\"]\n",
    "genel=genel.drop(\"DATE\",axis=1)\n",
    "genel.to_csv(r\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Data_Mining\\\\.users.txt\", index=False, header=True)\n",
    "print(genel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Code Value  User ID Hour Min Month Day  Year\n",
      "0        58   100        1    9  09    04  21  1991\n",
      "1        33   009        1    9  09    04  21  1991\n",
      "2        34   013        1    9  09    04  21  1991\n",
      "3        62   119        1   17  08    04  21  1991\n",
      "4        33   007        1   17  08    04  21  1991\n",
      "...     ...   ...      ...  ...  ..   ...  ..   ...\n",
      "29171    33   001       70   08  00    05  09  1989\n",
      "29172    34   007       70   08  00    05  09  1989\n",
      "29173    34   007       70   08  00    05  10  1989\n",
      "29174    34   007       70   08  00    05  11  1989\n",
      "29175    34   007       70   08  00    05  12  1989\n",
      "\n",
      "[29176 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(r\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Data_Mining\\\\29176-Date.txt\")\n",
    "\n",
    "#To be able to use timestamp function, we broke down the DATE and Time columns.\n",
    "new=data[\"DATE\"].str.split(\"-\", expand = True)\n",
    "new1=data[\"Time\"].str.split(\":\", expand = True)\n",
    "data[\"Hour\"]=new1[0]\n",
    "data[\"Min\"]=new1[1]\n",
    "data[\"Month\"]=new[0]\n",
    "data[\"Day\"]=new[1]\n",
    "data[\"Year\"]=new[2]\n",
    "#We dropped DATE and Time \n",
    "data=data.drop(columns=[\"DATE\",\"Time\"])\n",
    "\n",
    "#The dataset has been saved in the file namely final\n",
    "data.to_csv(r\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Data_Mining\\\\final.txt\", index=False, header=True )\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Code Value  User ID    Time_Stamp\n",
      "0        58   134       68  5.754528e+08\n",
      "1        34   020       68  5.754528e+08\n",
      "2        60   158       68  5.754672e+08\n",
      "3        62   258       68  5.754888e+08\n",
      "4        58   115       68  5.755392e+08\n",
      "...     ...   ...      ...           ...\n",
      "29171    33    21       29  1.000000e+15\n",
      "29172    33    22       29  1.000000e+15\n",
      "29173    33    3A       29  1.000000e+15\n",
      "29174    33    21       29  1.000000e+15\n",
      "29175    33    21       29  1.000000e+15\n",
      "\n",
      "[29176 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#Read the file again.\n",
    "data = pd.read_csv(r\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Data_Mining\\\\final.txt\")\n",
    "\n",
    "#To be able to use the timestamp function, we converted the columns into list\n",
    "Hour = data['Hour'].to_list()\n",
    "Min = data['Min'].to_list()\n",
    "Year = data['Year'].to_list()\n",
    "Month = data['Month'].to_list()\n",
    "Day = data['Day'].to_list()\n",
    "liste=[]\n",
    "for i in range(0,len(data)):\n",
    "\n",
    "#To be able to handle the missing values, try and except blocks have been used.\n",
    "    try:\n",
    "        ts = pd.Timestamp(year=int(Year[i]), month=int(Month[i]), day=int(Day[i]),\n",
    "                          hour=int(Hour[i]), minute=int(Min[i]))\n",
    "        a=ts.timestamp()\n",
    "        liste.append(float(a))\n",
    "    except:\n",
    "#If there is a missing value in rows, to maket he function work, we assign very #big values to the rows.\n",
    "        b=999999999999999\n",
    "        liste.append(b)\n",
    "data[\"Time_Stamp\"]=liste\n",
    "\n",
    "data=data.drop([\"Hour\",\"Min\",\"Month\",\"Day\",\"Year\"],axis=1)\n",
    "data.index=range(0,len(data))\n",
    "\n",
    "#Here, we sorted the data set according to timestamp.\n",
    "data=data.groupby(data.Time_Stamp.apply(type) != str).apply(lambda g: g.sort_values('Time_Stamp')).reset_index(drop = True)\n",
    "\n",
    "print(data)\n",
    "#Here, saved the data set in a file namely .dat\n",
    "data.to_csv(r\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Data_Mining\\\\.dat.txt\", index=False, header=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Code Value  User ID  Att_Code  Blood_Sugar  Food_Intake  Exercise\n",
      "0        58   100        1         1            1            0         0\n",
      "1        33   009        1         1            0            0         0\n",
      "2        34   013        1         1            0            0         0\n",
      "3        62   119        1         1            1            0         0\n",
      "4        33   007        1         1            0            0         0\n",
      "...     ...   ...      ...       ...          ...          ...       ...\n",
      "29325    33   001       70         1            0            0         0\n",
      "29326    34   007       70         1            0            0         0\n",
      "29327    34   007       70         1            0            0         0\n",
      "29328    34   007       70         1            0            0         0\n",
      "29329    34   007       70         1            0            0         0\n",
      "\n",
      "[29330 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Here, we recalled a file which contains 29330 rows. \n",
    "data = pd.read_csv(r\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Data_Mining\\\\29330.txt\")\n",
    "#To create attribute codes, we will use kodlar list.\n",
    "kodlar=[33,34,35,48,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72]\n",
    "\n",
    "#To create blood sugar measurement column, we will use blood list.\n",
    "blood=[48,57,58,59,60,61,62,63,64]\n",
    "\n",
    "#To create food intake measurement column, we will use food list.\n",
    "food=[66,67,68]\n",
    "\n",
    "#To create activity column, we will use exercise list.\n",
    "exercise=[69,70,71]\n",
    "data=data.drop(columns=[\"Time\",\"DATE\"])\n",
    "\n",
    "#We will assign 1-0 binary values in these lists.\n",
    "listeattribute=[]\n",
    "listeblood=[]\n",
    "listefood=[]\n",
    "listeexercise=[]\n",
    "\n",
    "for i in range(0,len(data)):\n",
    "    if data[\"Code\"][i] in kodlar:\n",
    "        value=1\n",
    "        listeattribute.append(value)\n",
    "    else:\n",
    "        value=0\n",
    "        listeattribute.append(value)\n",
    "data[\"Att_Code\"]=pd.Series(listeattribute)\n",
    "\n",
    "for i in range(0,len(data)):\n",
    "    if data[\"Code\"][i] in blood:\n",
    "        value=1\n",
    "        listeblood.append(value)\n",
    "    else:\n",
    "        value=0\n",
    "        listeblood.append(value)\n",
    "data[\"Blood_Sugar\"]=pd.Series(listeblood)\n",
    "\n",
    "for i in range(0,len(data)):\n",
    "    if data[\"Code\"][i] in food:\n",
    "        value=1\n",
    "        listefood.append(value)\n",
    "    else:\n",
    "        value=0\n",
    "        listefood.append(value)\n",
    "data[\"Food_Intake\"]=pd.Series(listefood)\n",
    "\n",
    "for i in range(0,len(data)):\n",
    "    if data[\"Code\"][i] in exercise:\n",
    "        value=1\n",
    "        listeexercise.append(value)\n",
    "    else:\n",
    "        value=0\n",
    "        listeexercise.append(value)\n",
    "data[\"Exercise\"]=pd.Series(listeexercise)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Att_Code  Blood_Sugar  Food_Intake  Exercise  Standard_M\n",
      "0             1            1            0         0           1\n",
      "1             1            0            0         0           0\n",
      "2             1            0            0         0           0\n",
      "3             1            1            0         0           0\n",
      "4             1            0            0         0           0\n",
      "...         ...          ...          ...       ...         ...\n",
      "29325         1            0            0         0           0\n",
      "29326         1            0            0         0           0\n",
      "29327         1            0            0         0           0\n",
      "29328         1            0            0         0           0\n",
      "29329         1            0            0         0           0\n",
      "\n",
      "[29330 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#To create standard measurement column, we need to replace meaningless entries #with 0\n",
    "data[\"Value\"]=data[\"Value\"].replace([\"0''\",\"0Hi\",\"3A\",\"0Lo\",np.nan],0)\n",
    "data[\"Value\"]=pd.to_numeric(data[\"Value\"])\n",
    "\n",
    "#To create standard measurement column, we will use standart_measurement list.\n",
    "standart_measurement=[58,59,61,63]\n",
    "\n",
    "#We will assign 1-0 binary values in this list.\n",
    "listestandart=[]\n",
    "\n",
    "count=0\n",
    "for i in data[\"Code\"]:\n",
    "    if i in standart_measurement:\n",
    "\t#58 is pre-breakfast blood sugar measurement code. Ranges in [70-100] is #considered normal \n",
    "        if i==58 and data[\"Value\"][count]>=70 and data[\"Value\"][count]<=100:\n",
    "            value=1\n",
    "            listestandart.append(value)\n",
    "            count+=1\n",
    "\t#The rest is post-meal blood sugar measurement code. Ranges in (100-125] #is considered normal\n",
    "        elif data[\"Value\"][count]>100 and data[\"Value\"][count]<=125:\n",
    "            value=1\n",
    "            listestandart.append(value)\n",
    "            count += 1\n",
    "        else:\n",
    "            value=0\n",
    "            listestandart.append(value)\n",
    "            count += 1\n",
    "\n",
    "#If the codes is not in the list, then assign 0.\n",
    "    else:\n",
    "        value = 0\n",
    "        listestandart.append(value)\n",
    "        count += 1\n",
    "data=data.drop(columns=[\"Code\",\"Value\", \"User ID\"])\n",
    "data[\"Standard_M\"]=pd.Series(listestandart)\n",
    "\n",
    "#Saving the dataset in a file namely .Attrs\n",
    "data.to_csv(r\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Data_Mining\\\\.Attrs.txt\", index=False, header=True)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
